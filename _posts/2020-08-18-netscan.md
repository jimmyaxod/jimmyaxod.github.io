# Netscan

Following on from yesterday, I tweaked the java portscanner, so that it's able to quickly try to connect to a large number of hosts at once, to see if any are responding.
Taking a set of hosts from the IPFS crawler, I can now periodically check on connectivity and 'health' of the network.

So, lets take the set of peers our IPFS crawler was able to connect to successfully. You should note that a peer may have more than once public address,
so some of these may point to the same peer. Especially in the case of having an ipv4 and ipv6.

|                 | Count |
| --------------- | ----- |
| Total peers     | 23193 |
| IPv6            | 10440 |
| IPv4            | 12753 |

When we attempt to connect via TCP, there's a concept of timeout... That is, how long do we wait until we give up?
Some peers respond quickly, some take a while to respond.

The maximum timeout under linux by default, is 20seconds. So trying to set our code to use a timeout longer than that will not help matters.
To change that, you can modify /proc/sys/net/ipv4/tcp_syn_retries

Here's some totals in terms of successful connections trying different timeout values for our scanner.

| Timeout        | Successful | Program execution time |
| -------------- | ---------- | ---------------------- |
|          100ms |        461 |                  715ms |
|          200ms |        682 |                  915ms |
|          300ms |        856 |                  979ms |
|          400ms |       1139 |                 1044ms |
|          500ms |       1306 |                 1167ms |
|         1000ms |       1396 |                 1667ms |
|         2000ms |       2089 |                 2658ms |
|         5000ms |       2880 |                 5759ms |
|        10000ms |       3247 |                10742ms |
|        20000ms |       3705 |                20713ms |

This is good, but are we really at the maximum chance of connection success with that 20 second timeout? Is there anything else we can do?

To get a better idea of what's happening under the hood, I modified the code to accurately measure each successful connections latency. 

![TCP Connect Latency](/images/tcp_connect_latency.png)

Now lets look at what Linux is doing under the hood.
When you call connect(), Linux sends out a SYN packet. Then after a second, it sends out another. It then doubles this time for subsequent retries.
So you get...

| Time |   Action |
| ---- | -------- |
|   0s | SYN sent |
|   1s | SYN sent |
|   3s | SYN sent |
|   7s | SYN sent |
|  15s | SYN sent |

As you can see in the graph this correlates exactly with the successful connections we get back.

If we wanted to though, we could modify our code to be more aggressive. Instead of sending 5 SYN packets over the 20 second timeout range, we could make it send out any number of them. Let's try that!

If we were being exact, we would want to cancel/restart a connection attempt after a specific time on a per connection basis. However, to keep things simple, I'm going to simply cancel/restart ALL ongoing connection attempts in one go. It doesn't matter much, just means that we may be resending a SYN a few ms earlier or later than we'd ideally want to.
It should be noted that once we cancel the connection attempts, any responses from the peer relating to THAT connection attempt will be dropped. So we potentially lose some connections there. We could of course not cancel the old ones, but we may quickly get bogged down in terms of open file handles etc.

![TCP Connect Latency Refresh](/images/tcp_connect_latency_refresh.png)

In the above data, I set 3 extra runs up, to refresh the pending connection attempts every 10s, 5s, and 2s.

Now lets look at the total successes from each of our runs.

| Run             | Success |      % |
| --------------- | ------- | ------ |
| 1               |    3955 |  17.05 |
| 2               |    4471 |  19.28 |
| 3               |    4061 |  17.51 |
| 4 (Refresh 10s) |    5065 |  21.84 |
| 5 (Refresh 5s)  |    6368 |  27.46 |
| 6 (Refresh 2s)  |    7251 |  31.26 |

As you can see, by sending out more SYNs, we have a higher chance of successful connections.

It should be noted that these tests were run on a consumer grade fibre connection with ipv4/ipv6 connectivity. It's quite possible that packets are being dropped that wouldn't be dropped in a different environment.

Here's some results from a Linode VPS

| Timeout | Refresh | Success |
| ------- | ------- | ------- |
|     20s |       - |   11452 |
|     20s |     10s |   11554 |
|     20s |      5s |   11562 |
|     20s |      2s |   11562 |

As you can see, the results here are far far better. Our connection attempt SYN packets are being delivered properly without drops.
